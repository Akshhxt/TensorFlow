{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMC2fGvYgJkGwjhWK8rkTw/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshhxt/TensorFlow/blob/main/Transfer_Learning_in_TensorFlow(2)_Fine_Tuning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning with TensorFlow Part 2: Fine-tuning\n",
        "\n",
        "In the previous section, we saw how we could leverage feature extraction transfer learning to get far better results on our Food Vision project than building our own models (even with less data).\n",
        "\n",
        "Now we're going to cover another type of transfer learning: fine-tuning.\n",
        "\n",
        "In **fine-tuning transfer learning** the pre-trained model weights from another model are unfrozen and tweaked during to better suit your own data.\n",
        "\n",
        "For feature extraction transfer learning, you may only train the top 1-3 layers of a pre-trained model with your own data, in fine-tuning transfer learning, you might train 1-3+ layers of a pre-trained model (where the '+' indicates that many or all of the layers could be trained).\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/05-transfer-learning-feature-extraction-vs-fine-tuning.png)\n",
        "*Feature extraction transfer learning vs. fine-tuning transfer learning. The main difference between the two is that in fine-tuning, more layers of the pre-trained model get unfrozen and tuned on custom data. This fine-tuning usually takes more data than feature extraction to be effective.*\n"
      ],
      "metadata": {
        "id": "tt-fBDyrL6TY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"
      ],
      "metadata": {
        "id": "SKmwd72nL67R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a779dc3-6d26-4597-ae97-90712a072eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Notebook last run (end-to-end): 2024-03-22 17:10:27.007562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tDIiM4761Kx",
        "outputId": "265837ab-29a2-4f40-c623-5d670d94a0d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Are we using a GPU? (if not & you're using Google Colab, go to Runtime -> Change Runtime Type -> Harware Accelerator: GPU )\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1VBj7FG62ha",
        "outputId": "ee83fb60-d00b-4746-cf1f-59a186d87828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Mar 22 17:10:27 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P0              28W /  70W |    105MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating helper functions\n",
        "\n",
        "Throughout your machine learning experiments, you'll likely come across snippets of code you want to use over and over again.\n",
        "\n",
        "For example, a plotting function which plots a model's `history` object (see `plot_loss_curves()` below).\n",
        "\n",
        "You could recreate these functions over and over again.\n",
        "\n",
        "But as you might've guessed, rewriting the same functions becomes tedious.\n",
        "\n",
        "One of the solutions is to store them in a helper script such as [`helper_functions.py`](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py). And then import the necesary functionality when you need it.\n",
        "\n",
        "For example, you might write:\n",
        "\n",
        "```\n",
        "from helper_functions import plot_loss_curves\n",
        "\n",
        "...\n",
        "\n",
        "plot_loss_curves(history)\n",
        "```\n",
        "\n",
        "Let's see what this looks like."
      ],
      "metadata": {
        "id": "hMWx_M6I66x4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get helper_functions.py script from course GitHub\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import helper functions we're going to use\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGKpezjJ64XO",
        "outputId": "cdc76412-069c-4bcf-a410-ed04355cb5f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-22 17:10:27--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.2’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-22 17:10:27 (98.6 MB/s) - ‘helper_functions.py.2’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10 Food Classes: Working with less data\n",
        "\n",
        "We saw in the [previous notebook](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb) that we could get great results with only 10% of the training data using transfer learning with TensorFlow Hub.\n",
        "\n",
        "In this notebook, we're going to continue to work with smaller subsets of the data, except this time we'll have a look at how we can use the in-built pretrained models within the [`tf.keras.applications`](https://www.tensorflow.org/api_docs/python/tf/keras/applications) module as well as how to fine-tune them to our own custom dataset.\n",
        "\n",
        "We'll also practice using a new but similar dataloader function to what we've used before, [`image_dataset_from_directory()`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory) which is part of the [`tf.keras.utils`](https://www.tensorflow.org/api_docs/python/tf/keras/utils) module.\n",
        "\n",
        "Finally, we'll also be practicing using the [Keras Functional API](https://keras.io/guides/functional_api/) for building deep learning models. The Functional API is a more flexible way to create models than the tf.keras.Sequential API.\n",
        "\n",
        "We'll explore each of these in more detail as we go.\n",
        "\n",
        "Let's start by downloading some data."
      ],
      "metadata": {
        "id": "PYCW80qw5xt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 10% of the data of the 10 classes\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "unzip_data(\"10_food_classes_10_percent.zip\")"
      ],
      "metadata": {
        "id": "b4qYMD-X69CA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88578b35-37b0-437d-bef4-3c3562e124c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-22 17:10:27--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.2.207, 2607:f8b0:4023:c0d::cf\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.2.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip.2’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   192MB/s    in 0.8s    \n",
            "\n",
            "2024-03-22 17:10:28 (192 MB/s) - ‘10_food_classes_10_percent.zip.2’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Walk through 10 percent data directory and list number of files\n",
        "walk_through_dir(\"10_food_classes_10_percent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIcvTjNJ50QW",
        "outputId": "8ccc9a3a-515b-4acc-c021-2082aa699f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test directories\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\""
      ],
      "metadata": {
        "id": "GMKeomGG510Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got some image data, we need a way of loading it into a TensorFlow compatible format.\n",
        "\n",
        "Previously, we've used the [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) class.\n",
        "\n",
        "However, as of August 2023, this class is deprecated and isn't recommended for future usage (it's too slow).\n",
        "\n",
        "Because of this, we'll move onto using `tf.keras.utils.image_dataset_from_directory()`.\n",
        "\n",
        "This method expects image data in the following file format:\n",
        "\n",
        "```\n",
        "Example of file structure\n",
        "\n",
        "10_food_classes_10_percent <- top level folder\n",
        "└───train <- training images\n",
        "│   └───pizza\n",
        "│   │   │   1008104.jpg\n",
        "│   │   │   1638227.jpg\n",
        "│   │   │   ...      \n",
        "│   └───steak\n",
        "│       │   1000205.jpg\n",
        "│       │   1647351.jpg\n",
        "│       │   ...\n",
        "│   \n",
        "└───test <- testing images\n",
        "│   └───pizza\n",
        "│   │   │   1001116.jpg\n",
        "│   │   │   1507019.jpg\n",
        "│   │   │   ...      \n",
        "│   └───steak\n",
        "│       │   100274.jpg\n",
        "│       │   1653815.jpg\n",
        "│       │   ...    \n",
        "```\n",
        "\n",
        "One of the main benefits of using [`tf.keras.prepreprocessing.image_dataset_from_directory()`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory) rather than `ImageDataGenerator` is that it creates a [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) object rather than a generator.\n",
        "\n",
        "The main advantage of this is the `tf.data.Dataset` API is much more efficient (faster) than the `ImageDataGenerator` API which is paramount for larger datasets.\n",
        "\n",
        "Let's see it in action."
      ],
      "metadata": {
        "id": "k702Bpkx56Ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data inputs\n",
        "import tensorflow as tf\n",
        "IMG_SIZE = (224, 224) # define image size\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
        "                                                                            image_size=IMG_SIZE,\n",
        "                                                                            label_mode=\"categorical\", # what type are the labels?\n",
        "                                                                            batch_size=32) # batch_size is 32 by default, this is generally a good number\n",
        "test_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
        "                                                                           image_size=IMG_SIZE,\n",
        "                                                                           label_mode=\"categorical\")"
      ],
      "metadata": {
        "id": "93bgmmEL54K7",
        "outputId": "dd2acc3f-75c8-4842-8300-95ed36b9ca57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wonderful! Looks like our dataloaders have found the correct number of images for each dataset.\n",
        "\n",
        "For now, the main parameters we're concerned about in the `image_dataset_from_directory()` funtion are:\n",
        "* `directory` - the filepath of the target directory we're loading images in from.\n",
        "* `image_size` - the target size of the images we're going to load in (height, width).\n",
        "* `batch_size` - the batch size of the images we're going to load in. For example if the `batch_size` is 32 (the default), batches of 32 images and labels at a time will be passed to the model.\n",
        "\n",
        "There are more we could play around with if we needed to [in the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory).\n",
        "\n",
        "If we check the training data datatype we should see it as a `BatchDataset` with shapes relating to our data."
      ],
      "metadata": {
        "id": "ETInXRCJJ_bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the training data datatype\n",
        "train_data_10_percent"
      ],
      "metadata": {
        "id": "SMBxeHyq58zN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34bd7466-b822-49c7-feec-609611d57699"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above output:\n",
        "\n",
        "* `(None, 224, 224, 3)` refers to the tensor shape of our images where `None` is the batch size, `224` is the height (and width) and `3` is the color channels (red, green, blue).\n",
        "* `(None, 10)` refers to the tensor shape of the labels where `None` is the batch size and `10` is the number of possible labels (the 10 different food classes).\n",
        "* Both image tensors and labels are of the datatype `tf.float32`.\n",
        "\n",
        "The `batch_size` is `None` due to it only being used during model training. You can think of `None` as a placeholder waiting to be filled with the `batch_size` parameter from `image_dataset_from_directory()`.\n",
        "\n",
        "Another benefit of using the `tf.data.Dataset` API are the assosciated methods which come with it.\n",
        "\n",
        "For example, if we want to find the name of the classes we were working with, we could use the `class_names` attribute."
      ],
      "metadata": {
        "id": "7tc_pTDPKE29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the class names of our dataset\n",
        "train_data_10_percent.class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6XeGPs6KCrT",
        "outputId": "4ba1f05a-4017-45ab-ae95-a10ef12f4c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See an example batch of data\n",
        "for images, labels in train_data_10_percent.take(1):\n",
        "  print(images, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjJM068WKG5_",
        "outputId": "8e7cc6bf-29d6-4efc-df84-b6743dca370c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[[ 55.65848     7.658482    3.658482 ]\n",
            "   [ 57.587055    8.658483    4.0470343]\n",
            "   [ 67.301346    8.658483    6.872768 ]\n",
            "   ...\n",
            "   [ 61.517395    6.482607    5.       ]\n",
            "   [ 59.127037    6.317119    4.7056804]\n",
            "   [ 53.70893     6.7804646   4.423287 ]]\n",
            "\n",
            "  [[ 54.950893    7.0245533   3.7458544]\n",
            "   [ 56.857143    7.9285717   3.9285717]\n",
            "   [ 65.64286     7.          5.214286 ]\n",
            "   ...\n",
            "   [ 57.970184    7.005261    5.581994 ]\n",
            "   [ 55.900497    6.092487    5.186728 ]\n",
            "   [ 51.18743     6.015784    5.6358085]]\n",
            "\n",
            "  [[ 53.          8.          5.       ]\n",
            "   [ 56.149555    8.029655    4.0801973]\n",
            "   [ 65.0869      7.707589    6.629464 ]\n",
            "   ...\n",
            "   [ 54.10699     7.062653    6.707589 ]\n",
            "   [ 52.61236     6.2715206   7.6361475]\n",
            "   [ 46.1232      6.4407034   5.8120317]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[  6.          6.          6.       ]\n",
            "   [  6.          6.          6.       ]\n",
            "   [  6.          6.          6.       ]\n",
            "   ...\n",
            "   [ 28.093874   27.981932   25.584839 ]\n",
            "   [ 29.578936   28.698812   25.334202 ]\n",
            "   [ 33.187973   29.187973   26.187973 ]]\n",
            "\n",
            "  [[  6.          6.          6.       ]\n",
            "   [  6.          6.          6.       ]\n",
            "   [  6.          6.          6.       ]\n",
            "   ...\n",
            "   [ 15.7782755  18.93821    26.233543 ]\n",
            "   [ 24.31247    25.216492   26.97897  ]\n",
            "   [ 28.765503   27.691895   23.71643  ]]\n",
            "\n",
            "  [[  6.          6.          6.       ]\n",
            "   [  6.          6.          6.       ]\n",
            "   [  6.          6.          6.       ]\n",
            "   ...\n",
            "   [ 10.357208   14.785736   26.14635  ]\n",
            "   [ 21.895447   21.555847   25.90416  ]\n",
            "   [ 27.511927   25.235193   21.740376 ]]]\n",
            "\n",
            "\n",
            " [[[ 78.71428    78.71428    54.714287 ]\n",
            "   [ 78.331635   77.734695   55.525513 ]\n",
            "   [ 78.14285    77.14285    57.57143  ]\n",
            "   ...\n",
            "   [ 93.07652    83.50505    73.29079  ]\n",
            "   [ 96.096954   82.096954   73.096954 ]\n",
            "   [101.48474    84.48474    76.48474  ]]\n",
            "\n",
            "  [[ 81.02041    78.02551    55.357143 ]\n",
            "   [ 79.         77.         56.       ]\n",
            "   [ 77.372444   74.602036   57.872448 ]\n",
            "   ...\n",
            "   [ 95.51535    83.15814    73.94388  ]\n",
            "   [ 97.86224    83.86224    74.86224  ]\n",
            "   [100.95409    83.95409    75.95409  ]]\n",
            "\n",
            "  [[ 84.21938    77.14285    58.142857 ]\n",
            "   [ 81.85714    76.71429    57.785713 ]\n",
            "   [ 79.90816    76.188774   62.       ]\n",
            "   ...\n",
            "   [ 99.57147    85.90817    74.73982  ]\n",
            "   [101.198975   87.198975   76.198975 ]\n",
            "   [101.49489    85.13775    75.352036 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[119.79087   116.500084  109.862366 ]\n",
            "   [126.28036   123.05079   115.780426 ]\n",
            "   [130.84691   127.58673   120.63269  ]\n",
            "   ...\n",
            "   [109.69392   124.47965   165.05113  ]\n",
            "   [108.086685  122.87242   163.4439   ]\n",
            "   [104.362144  119.14788   159.71935  ]]\n",
            "\n",
            "  [[112.887856  117.17362   118.316505 ]\n",
            "   [121.903015  126.18878   127.331665 ]\n",
            "   [120.25511   124.54088   125.68376  ]\n",
            "   ...\n",
            "   [103.37239   120.37239   163.37239  ]\n",
            "   [101.92856   118.92856   161.92856  ]\n",
            "   [103.785675  120.785675  163.78568  ]]\n",
            "\n",
            "  [[115.33194   126.40347   135.40347  ]\n",
            "   [121.542274  132.6138    141.6138   ]\n",
            "   [111.633194  122.70473   131.70473  ]\n",
            "   ...\n",
            "   [104.489914  121.489914  165.48991  ]\n",
            "   [105.4288    122.4288    166.4288   ]\n",
            "   [101.943954  118.943954  162.94395  ]]]\n",
            "\n",
            "\n",
            " [[[ 51.         61.         63.       ]\n",
            "   [ 51.02551    61.02551    63.02551  ]\n",
            "   [ 47.566326   57.566326   59.35204  ]\n",
            "   ...\n",
            "   [ 72.99482    38.780556   13.137762 ]\n",
            "   [ 71.30614    37.234695   10.826511 ]\n",
            "   [ 75.015366   37.301006    7.5866523]]\n",
            "\n",
            "  [[ 45.85714    55.85714    57.85714  ]\n",
            "   [ 48.142857   58.142857   60.142857 ]\n",
            "   [ 46.142857   56.142857   57.92857  ]\n",
            "   ...\n",
            "   [ 72.71947    38.903122   11.091982 ]\n",
            "   [ 80.44389    46.372456   18.295897 ]\n",
            "   [ 79.93368    42.86215    10.504971 ]]\n",
            "\n",
            "  [[ 41.785713   51.357143   53.357143 ]\n",
            "   [ 41.85714    51.42857    53.42857  ]\n",
            "   [ 37.954082   47.52551    48.739796 ]\n",
            "   ...\n",
            "   [ 67.07134    35.642815    6.214286 ]\n",
            "   [ 69.60207    36.45919     5.387748 ]\n",
            "   [ 73.29089    36.576538    1.7907896]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 94.275635   35.13282    11.571625 ]\n",
            "   [149.01051    91.16875    64.45444  ]\n",
            "   [158.34709    98.30119    69.91853  ]\n",
            "   ...\n",
            "   [164.33641    17.265085   27.050821 ]\n",
            "   [164.29086    23.64813    32.57669  ]\n",
            "   [154.15765    17.44349    24.948578 ]]\n",
            "\n",
            "  [[ 88.12768    27.581728    2.020425 ]\n",
            "   [117.601906   56.392685   27.51514  ]\n",
            "   [105.841675   44.555912   15.688587 ]\n",
            "   ...\n",
            "   [163.62761    22.08687    31.071564 ]\n",
            "   [157.50482    20.642609   30.642609 ]\n",
            "   [136.88753     1.790694   11.290633 ]]\n",
            "\n",
            "  [[108.4796     43.12242    10.790754 ]\n",
            "   [110.15304    44.79586    13.989675 ]\n",
            "   [ 97.933716   30.704102    4.2092104]\n",
            "   ...\n",
            "   [161.02525    20.964056   29.673264 ]\n",
            "   [137.05594     1.8621356  11.127373 ]\n",
            "   [130.41817     0.          5.4181633]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[211.65817   172.65817   129.65817  ]\n",
            "   [227.11736   190.02551   146.07144  ]\n",
            "   [227.35715   193.57143   148.57143  ]\n",
            "   ...\n",
            "   [249.91838   154.28575    49.494926 ]\n",
            "   [249.31122   159.68883    52.928596 ]\n",
            "   [249.58672   164.55617    56.14289  ]]\n",
            "\n",
            "  [[215.68878   174.16325   128.59184  ]\n",
            "   [224.06122   185.92857   140.86226  ]\n",
            "   [225.7296    189.55612   144.5      ]\n",
            "   ...\n",
            "   [245.85716   146.00002    34.443874 ]\n",
            "   [245.27553   149.37247    37.780647 ]\n",
            "   [245.78568   152.18884    41.857178 ]]\n",
            "\n",
            "  [[219.80103   175.7857    126.43367  ]\n",
            "   [223.78572   181.65817   133.15817  ]\n",
            "   [226.04591   188.30612   141.26021  ]\n",
            "   ...\n",
            "   [247.2602    143.42857    27.923456 ]\n",
            "   [247.        142.7704     29.38776  ]\n",
            "   [244.93364   142.0765     31.571428 ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[148.92854   155.50511   192.648    ]\n",
            "   [145.37242   154.78574   191.07143  ]\n",
            "   [144.61734   154.2602    193.04591  ]\n",
            "   ...\n",
            "   [227.85706   208.40804   147.6682   ]\n",
            "   [215.40308   188.31631   120.64807  ]\n",
            "   [218.22456   187.72964   129.36745  ]]\n",
            "\n",
            "  [[143.66325   155.66837   191.       ]\n",
            "   [142.86223   154.86223   192.86223  ]\n",
            "   [142.21428   156.21428   193.21428  ]\n",
            "   ...\n",
            "   [237.2551    217.25497   176.18347  ]\n",
            "   [224.78058   198.91325   141.62749  ]\n",
            "   [216.94896   189.35207   123.443794 ]]\n",
            "\n",
            "  [[144.0715    158.0715    195.0715   ]\n",
            "   [141.4286    155.4286    192.4286   ]\n",
            "   [140.28564   154.28564   191.28564  ]\n",
            "   ...\n",
            "   [245.5613    225.63261   197.19385  ]\n",
            "   [237.31119   212.35721   162.14273  ]\n",
            "   [219.7704    193.12758   122.21411  ]]]\n",
            "\n",
            "\n",
            " [[[122.85204    60.852043    9.852041 ]\n",
            "   [120.40306    63.188778    9.066326 ]\n",
            "   [119.11735    64.7602      7.8265305]\n",
            "   ...\n",
            "   [217.21432   204.21432   188.21432  ]\n",
            "   [216.95407   203.95407   187.95407  ]\n",
            "   [216.71432   203.71432   187.71432  ]]\n",
            "\n",
            "  [[114.71429    54.714287    3.3775506]\n",
            "   [115.56632    58.35204     3.4234679]\n",
            "   [124.12245    69.321434   11.724493 ]\n",
            "   ...\n",
            "   [217.78574   204.78574   188.78574  ]\n",
            "   [216.92856   203.92856   187.92856  ]\n",
            "   [217.26024   204.26024   188.26024  ]]\n",
            "\n",
            "  [[123.28571    63.928574   11.714287 ]\n",
            "   [129.2296     72.22959    17.229593 ]\n",
            "   [131.77042    75.12755    17.913265 ]\n",
            "   ...\n",
            "   [217.21428   204.21428   188.21428  ]\n",
            "   [217.05614   204.05614   188.05614  ]\n",
            "   [219.63782   206.63782   190.63782  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[253.78574   254.78574   248.78574  ]\n",
            "   [254.        255.        249.       ]\n",
            "   [254.        255.        249.       ]\n",
            "   ...\n",
            "   [249.16835   239.16835   229.16835  ]\n",
            "   [254.55617   244.55617   234.55617  ]\n",
            "   [249.29582   239.29582   229.29582  ]]\n",
            "\n",
            "  [[254.40308   255.        247.40308  ]\n",
            "   [254.        255.        247.       ]\n",
            "   [253.        254.        246.       ]\n",
            "   ...\n",
            "   [250.15309   240.15309   230.15309  ]\n",
            "   [248.27046   238.27046   228.27046  ]\n",
            "   [252.54596   242.54596   232.54596  ]]\n",
            "\n",
            "  [[255.        255.        248.       ]\n",
            "   [254.07143   255.        247.07143  ]\n",
            "   [253.        254.        246.       ]\n",
            "   ...\n",
            "   [250.95912   240.95912   230.95912  ]\n",
            "   [251.64793   241.64793   231.64793  ]\n",
            "   [250.94395   240.94395   230.94395  ]]]\n",
            "\n",
            "\n",
            " [[[ 58.495533   55.495533   22.874043 ]\n",
            "   [ 67.03874    65.03874    26.110172 ]\n",
            "   [ 69.07063    66.17299    35.936382 ]\n",
            "   ...\n",
            "   [ 77.68969   109.95085   147.16737  ]\n",
            "   [ 74.18972   106.45088   143.6674   ]\n",
            "   [ 70.54681   102.80797   140.02449  ]]\n",
            "\n",
            "  [[ 66.0625     63.566166   27.924107 ]\n",
            "   [ 72.408646   70.408646   29.969069 ]\n",
            "   [ 79.40562    76.97481    41.175224 ]\n",
            "   ...\n",
            "   [ 79.21201   112.21201   147.212    ]\n",
            "   [ 75.71204   108.71204   143.71204  ]\n",
            "   [ 72.06913   105.06913   140.06912  ]]\n",
            "\n",
            "  [[ 64.19834    64.19834    26.912628 ]\n",
            "   [ 69.79162    68.78571    25.021843 ]\n",
            "   [ 81.766266   80.0059     36.146366 ]\n",
            "   ...\n",
            "   [ 79.42853   112.42853   146.81693  ]\n",
            "   [ 75.92856   108.92856   143.31696  ]\n",
            "   [ 72.285645  105.285645  139.67404  ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 91.35065    95.56906   107.56906  ]\n",
            "   [ 88.80873    87.240845  103.4811   ]\n",
            "   [ 91.051346   92.26563   112.47992  ]\n",
            "   ...\n",
            "   [ 80.61157    79.37131    87.79462  ]\n",
            "   [ 71.446846   69.49644    80.34765  ]\n",
            "   [ 69.662964   68.662964   75.0561   ]]\n",
            "\n",
            "  [[ 95.00081    96.35124   109.84615  ]\n",
            "   [ 92.75031    92.15242   110.0405   ]\n",
            "   [103.523605  105.72099   125.33658  ]\n",
            "   ...\n",
            "   [ 75.39683    74.39683    81.9683   ]\n",
            "   [ 69.7702     67.841644   78.62732  ]\n",
            "   [ 67.217995   66.217995   72.140656 ]]\n",
            "\n",
            "  [[ 96.54367    95.27979   110.565506 ]\n",
            "   [ 87.48267    88.33981   107.71199  ]\n",
            "   [ 98.73197   103.479935  122.00495  ]\n",
            "   ...\n",
            "   [ 72.4754     71.4754     79.046875 ]\n",
            "   [ 70.453094   69.21061    77.93806  ]\n",
            "   [ 66.978264   65.978264   71.621086 ]]]], shape=(32, 224, 224, 3), dtype=float32) tf.Tensor(\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]], shape=(32, 10), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice how the image arrays come out as tensors of pixel values where as the labels come out as one-hot encodings (e.g. `[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]` for `hamburger`)."
      ],
      "metadata": {
        "id": "JLA3bPGLKL58"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sAALkDqzKIqe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}