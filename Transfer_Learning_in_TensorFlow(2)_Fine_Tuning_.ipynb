{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akshhxt/TensorFlow/blob/main/Transfer_Learning_in_TensorFlow(2)_Fine_Tuning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tt-fBDyrL6TY"
      },
      "source": [
        "# Transfer Learning with TensorFlow Part 2: Fine-tuning\n",
        "\n",
        "In the previous section, we saw how we could leverage feature extraction transfer learning to get far better results on our Food Vision project than building our own models (even with less data).\n",
        "\n",
        "Now we're going to cover another type of transfer learning: fine-tuning.\n",
        "\n",
        "In **fine-tuning transfer learning** the pre-trained model weights from another model are unfrozen and tweaked during to better suit your own data.\n",
        "\n",
        "For feature extraction transfer learning, you may only train the top 1-3 layers of a pre-trained model with your own data, in fine-tuning transfer learning, you might train 1-3+ layers of a pre-trained model (where the '+' indicates that many or all of the layers could be trained).\n",
        "\n",
        "![](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/05-transfer-learning-feature-extraction-vs-fine-tuning.png)\n",
        "*Feature extraction transfer learning vs. fine-tuning transfer learning. The main difference between the two is that in fine-tuning, more layers of the pre-trained model get unfrozen and tuned on custom data. This fine-tuning usually takes more data than feature extraction to be effective.*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKmwd72nL67R",
        "outputId": "a951d5b4-e4a4-446e-b5fe-a3455786a711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Notebook last run (end-to-end): 2024-03-28 16:05:34.193475\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tDIiM4761Kx",
        "outputId": "4d292636-6408-4741-cb0b-90b1768bf3a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1VBj7FG62ha",
        "outputId": "ee3a6696-6b46-446f-9f4c-01f6c2295afe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Mar 28 16:05:39 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Are we using a GPU? (if not & you're using Google Colab, go to Runtime -> Change Runtime Type -> Harware Accelerator: GPU )\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMWx_M6I66x4"
      },
      "source": [
        "## Creating helper functions\n",
        "\n",
        "Throughout your machine learning experiments, you'll likely come across snippets of code you want to use over and over again.\n",
        "\n",
        "For example, a plotting function which plots a model's `history` object (see `plot_loss_curves()` below).\n",
        "\n",
        "You could recreate these functions over and over again.\n",
        "\n",
        "But as you might've guessed, rewriting the same functions becomes tedious.\n",
        "\n",
        "One of the solutions is to store them in a helper script such as [`helper_functions.py`](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py). And then import the necesary functionality when you need it.\n",
        "\n",
        "For example, you might write:\n",
        "\n",
        "```\n",
        "from helper_functions import plot_loss_curves\n",
        "\n",
        "...\n",
        "\n",
        "plot_loss_curves(history)\n",
        "```\n",
        "\n",
        "Let's see what this looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGKpezjJ64XO",
        "outputId": "ca47bff3-ddb2-4b7e-cdf2-8e20fd95fade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-03-28 16:05:40--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-28 16:05:40 (59.3 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get helper_functions.py script from course GitHub\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import helper functions we're going to use\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYCW80qw5xt7"
      },
      "source": [
        "## 10 Food Classes: Working with less data\n",
        "\n",
        "We saw in the [previous notebook](https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/04_transfer_learning_in_tensorflow_part_1_feature_extraction.ipynb) that we could get great results with only 10% of the training data using transfer learning with TensorFlow Hub.\n",
        "\n",
        "In this notebook, we're going to continue to work with smaller subsets of the data, except this time we'll have a look at how we can use the in-built pretrained models within the [`tf.keras.applications`](https://www.tensorflow.org/api_docs/python/tf/keras/applications) module as well as how to fine-tune them to our own custom dataset.\n",
        "\n",
        "We'll also practice using a new but similar dataloader function to what we've used before, [`image_dataset_from_directory()`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory) which is part of the [`tf.keras.utils`](https://www.tensorflow.org/api_docs/python/tf/keras/utils) module.\n",
        "\n",
        "Finally, we'll also be practicing using the [Keras Functional API](https://keras.io/guides/functional_api/) for building deep learning models. The Functional API is a more flexible way to create models than the tf.keras.Sequential API.\n",
        "\n",
        "We'll explore each of these in more detail as we go.\n",
        "\n",
        "Let's start by downloading some data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4qYMD-X69CA",
        "outputId": "16225a94-6f80-4210-da9f-a1a2f983946f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-03-28 16:05:41--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.101.207, 142.250.141.207, 142.251.2.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.101.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   196MB/s    in 0.8s    \n",
            "\n",
            "2024-03-28 16:05:42 (196 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get 10% of the data of the 10 classes\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "unzip_data(\"10_food_classes_10_percent.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIcvTjNJ50QW",
        "outputId": "191d8173-9bf7-42eb-ab12-d7ff83077b00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n"
          ]
        }
      ],
      "source": [
        "# Walk through 10 percent data directory and list number of files\n",
        "walk_through_dir(\"10_food_classes_10_percent\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMKeomGG510Z"
      },
      "outputs": [],
      "source": [
        "# Create training and test directories\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k702Bpkx56Ab"
      },
      "source": [
        "Now we've got some image data, we need a way of loading it into a TensorFlow compatible format.\n",
        "\n",
        "Previously, we've used the [`ImageDataGenerator`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) class.\n",
        "\n",
        "However, as of August 2023, this class is deprecated and isn't recommended for future usage (it's too slow).\n",
        "\n",
        "Because of this, we'll move onto using `tf.keras.utils.image_dataset_from_directory()`.\n",
        "\n",
        "This method expects image data in the following file format:\n",
        "\n",
        "```\n",
        "Example of file structure\n",
        "\n",
        "10_food_classes_10_percent <- top level folder\n",
        "└───train <- training images\n",
        "│   └───pizza\n",
        "│   │   │   1008104.jpg\n",
        "│   │   │   1638227.jpg\n",
        "│   │   │   ...      \n",
        "│   └───steak\n",
        "│       │   1000205.jpg\n",
        "│       │   1647351.jpg\n",
        "│       │   ...\n",
        "│   \n",
        "└───test <- testing images\n",
        "│   └───pizza\n",
        "│   │   │   1001116.jpg\n",
        "│   │   │   1507019.jpg\n",
        "│   │   │   ...      \n",
        "│   └───steak\n",
        "│       │   100274.jpg\n",
        "│       │   1653815.jpg\n",
        "│       │   ...    \n",
        "```\n",
        "\n",
        "One of the main benefits of using [`tf.keras.prepreprocessing.image_dataset_from_directory()`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory) rather than `ImageDataGenerator` is that it creates a [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) object rather than a generator.\n",
        "\n",
        "The main advantage of this is the `tf.data.Dataset` API is much more efficient (faster) than the `ImageDataGenerator` API which is paramount for larger datasets.\n",
        "\n",
        "Let's see it in action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93bgmmEL54K7",
        "outputId": "49d70d97-0c6e-4ff0-8c13-3b01892631f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "# Create data inputs\n",
        "import tensorflow as tf\n",
        "IMG_SIZE = (224, 224) # define image size\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
        "                                                                            image_size=IMG_SIZE,\n",
        "                                                                            label_mode=\"categorical\", # what type are the labels?\n",
        "                                                                            batch_size=32) # batch_size is 32 by default, this is generally a good number\n",
        "test_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
        "                                                                           image_size=IMG_SIZE,\n",
        "                                                                           label_mode=\"categorical\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETInXRCJJ_bl"
      },
      "source": [
        "Wonderful! Looks like our dataloaders have found the correct number of images for each dataset.\n",
        "\n",
        "For now, the main parameters we're concerned about in the `image_dataset_from_directory()` funtion are:\n",
        "* `directory` - the filepath of the target directory we're loading images in from.\n",
        "* `image_size` - the target size of the images we're going to load in (height, width).\n",
        "* `batch_size` - the batch size of the images we're going to load in. For example if the `batch_size` is 32 (the default), batches of 32 images and labels at a time will be passed to the model.\n",
        "\n",
        "There are more we could play around with if we needed to [in the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/utils/image_dataset_from_directory).\n",
        "\n",
        "If we check the training data datatype we should see it as a `BatchDataset` with shapes relating to our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMBxeHyq58zN",
        "outputId": "17e3c20a-b2da-4e40-d4a7-bcf7d55ebb43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the training data datatype\n",
        "train_data_10_percent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tc_pTDPKE29"
      },
      "source": [
        "In the above output:\n",
        "\n",
        "* `(None, 224, 224, 3)` refers to the tensor shape of our images where `None` is the batch size, `224` is the height (and width) and `3` is the color channels (red, green, blue).\n",
        "* `(None, 10)` refers to the tensor shape of the labels where `None` is the batch size and `10` is the number of possible labels (the 10 different food classes).\n",
        "* Both image tensors and labels are of the datatype `tf.float32`.\n",
        "\n",
        "The `batch_size` is `None` due to it only being used during model training. You can think of `None` as a placeholder waiting to be filled with the `batch_size` parameter from `image_dataset_from_directory()`.\n",
        "\n",
        "Another benefit of using the `tf.data.Dataset` API are the assosciated methods which come with it.\n",
        "\n",
        "For example, if we want to find the name of the classes we were working with, we could use the `class_names` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6XeGPs6KCrT",
        "outputId": "a50ed67a-0232-45ce-ecc7-7e44c24936e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['chicken_curry',\n",
              " 'chicken_wings',\n",
              " 'fried_rice',\n",
              " 'grilled_salmon',\n",
              " 'hamburger',\n",
              " 'ice_cream',\n",
              " 'pizza',\n",
              " 'ramen',\n",
              " 'steak',\n",
              " 'sushi']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check out the class names of our dataset\n",
        "train_data_10_percent.class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjJM068WKG5_",
        "outputId": "b21b936b-a70f-4745-a9b4-ea3577f11a52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[[[9.50000000e+01 6.20000000e+01 4.50000000e+01]\n",
            "   [9.50000000e+01 6.20000000e+01 4.50000000e+01]\n",
            "   [9.60559616e+01 6.30559616e+01 4.60559616e+01]\n",
            "   ...\n",
            "   [6.69874907e+00 5.91301298e+00 4.34154081e+00]\n",
            "   [4.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [5.00000000e+00 1.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[9.50000000e+01 6.20000000e+01 4.50000000e+01]\n",
            "   [9.57275238e+01 6.27275200e+01 4.57275200e+01]\n",
            "   [9.62142868e+01 6.32142868e+01 4.62142868e+01]\n",
            "   ...\n",
            "   [7.47266579e+00 6.68692970e+00 5.11545753e+00]\n",
            "   [4.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [5.00000000e+00 1.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[9.50000000e+01 6.20000000e+01 4.50000000e+01]\n",
            "   [9.60000000e+01 6.30000000e+01 4.60000000e+01]\n",
            "   [9.70000000e+01 6.40000000e+01 4.70000000e+01]\n",
            "   ...\n",
            "   [7.85705566e+00 7.07131958e+00 5.49984741e+00]\n",
            "   [4.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            "   [4.69419622e+00 6.94196224e-01 0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.64305786e+02 1.61305786e+02 1.28305786e+02]\n",
            "   [1.64305786e+02 1.61305786e+02 1.28305786e+02]\n",
            "   [1.65454544e+02 1.62454544e+02 1.29454544e+02]\n",
            "   ...\n",
            "   [1.34571472e+02 1.37000000e+02 1.36000000e+02]\n",
            "   [1.34000000e+02 1.36000000e+02 1.35000000e+02]\n",
            "   [1.34000000e+02 1.36000000e+02 1.35000000e+02]]\n",
            "\n",
            "  [[1.64216522e+02 1.61216522e+02 1.28216522e+02]\n",
            "   [1.64015472e+02 1.61015472e+02 1.28015472e+02]\n",
            "   [1.64384399e+02 1.61384399e+02 1.28384399e+02]\n",
            "   ...\n",
            "   [1.34955872e+02 1.37384399e+02 1.36384399e+02]\n",
            "   [1.34944031e+02 1.36944031e+02 1.35944031e+02]\n",
            "   [1.33922668e+02 1.35922668e+02 1.34922668e+02]]\n",
            "\n",
            "  [[1.66002747e+02 1.63002747e+02 1.30002747e+02]\n",
            "   [1.64810287e+02 1.61810287e+02 1.28810287e+02]\n",
            "   [1.65738861e+02 1.62738861e+02 1.29738861e+02]\n",
            "   ...\n",
            "   [1.36310333e+02 1.38738861e+02 1.37738861e+02]\n",
            "   [1.35686081e+02 1.37686081e+02 1.36686081e+02]\n",
            "   [1.33642822e+02 1.35642822e+02 1.34642822e+02]]]\n",
            "\n",
            "\n",
            " [[[1.05714279e+02 8.47142792e+01 5.57142868e+01]\n",
            "   [1.05045921e+02 8.40459213e+01 5.70459175e+01]\n",
            "   [9.90000000e+01 7.63571396e+01 5.27857170e+01]\n",
            "   ...\n",
            "   [1.88622589e+01 1.48622589e+01 3.86225891e+00]\n",
            "   [1.90255146e+01 1.50255146e+01 4.02551508e+00]\n",
            "   [1.93571434e+01 1.53571424e+01 4.35714293e+00]]\n",
            "\n",
            "  [[1.07331627e+02 8.62602005e+01 5.94744911e+01]\n",
            "   [1.08928574e+02 8.69285736e+01 6.29948997e+01]\n",
            "   [1.03015305e+02 8.03724442e+01 5.80153046e+01]\n",
            "   ...\n",
            "   [2.00000000e+01 1.60000000e+01 5.00000000e+00]\n",
            "   [2.00714283e+01 1.60714283e+01 5.07142830e+00]\n",
            "   [2.10000000e+01 1.70000000e+01 6.00000000e+00]]\n",
            "\n",
            "  [[1.07785713e+02 8.57857132e+01 6.25714264e+01]\n",
            "   [1.09714287e+02 8.77142868e+01 6.61581650e+01]\n",
            "   [1.05882652e+02 8.32397995e+01 6.21173439e+01]\n",
            "   ...\n",
            "   [2.07857132e+01 1.67857132e+01 5.78571415e+00]\n",
            "   [2.10000000e+01 1.70000000e+01 6.00000000e+00]\n",
            "   [2.17857132e+01 1.77857132e+01 6.78571415e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[4.35714293e+00 5.35714293e+00 3.57142806e-01]\n",
            "   [4.00000000e+00 5.00000000e+00 0.00000000e+00]\n",
            "   [6.61734009e+00 7.61734009e+00 2.61734009e+00]\n",
            "   ...\n",
            "   [8.00000000e+00 8.00000000e+00 0.00000000e+00]\n",
            "   [8.00000000e+00 8.00000000e+00 0.00000000e+00]\n",
            "   [8.00000000e+00 8.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[4.35714293e+00 5.35714293e+00 3.57142806e-01]\n",
            "   [4.00000000e+00 5.00000000e+00 0.00000000e+00]\n",
            "   [5.80101633e+00 6.80101633e+00 1.80101657e+00]\n",
            "   ...\n",
            "   [8.00000000e+00 8.00000000e+00 0.00000000e+00]\n",
            "   [8.00000000e+00 8.00000000e+00 0.00000000e+00]\n",
            "   [8.00000000e+00 8.00000000e+00 0.00000000e+00]]\n",
            "\n",
            "  [[5.35714293e+00 6.35714293e+00 1.35714281e+00]\n",
            "   [4.00000000e+00 5.00000000e+00 0.00000000e+00]\n",
            "   [4.78571415e+00 5.78571415e+00 7.85714149e-01]\n",
            "   ...\n",
            "   [7.00000000e+00 7.00000000e+00 0.00000000e+00]\n",
            "   [7.00000000e+00 7.00000000e+00 0.00000000e+00]\n",
            "   [7.00000000e+00 7.00000000e+00 0.00000000e+00]]]\n",
            "\n",
            "\n",
            " [[[1.49857147e+02 7.59285736e+01 1.75714302e+01]\n",
            "   [1.61760208e+02 7.99744949e+01 2.39030628e+01]\n",
            "   [1.72913269e+02 8.11938782e+01 2.79795895e+01]\n",
            "   ...\n",
            "   [1.05086952e+02 6.13012161e+01 5.74441605e+01]\n",
            "   [1.20055756e+02 7.09843140e+01 7.71986389e+01]\n",
            "   [1.00315987e+02 4.83159866e+01 6.06731300e+01]]\n",
            "\n",
            "  [[1.56948975e+02 8.69030609e+01 2.49030609e+01]\n",
            "   [1.70219391e+02 9.05051041e+01 3.14336758e+01]\n",
            "   [1.66729584e+02 7.75867386e+01 2.16581631e+01]\n",
            "   ...\n",
            "   [1.08423416e+02 6.36223717e+01 5.78112297e+01]\n",
            "   [1.04806206e+02 5.48010864e+01 5.80205002e+01]\n",
            "   [1.05719078e+02 5.27190819e+01 6.08619385e+01]]\n",
            "\n",
            "  [[1.41336731e+02 7.55510254e+01 1.64081650e+01]\n",
            "   [1.50147964e+02 7.37193909e+01 1.84336739e+01]\n",
            "   [1.54591827e+02 6.95459137e+01 1.66173477e+01]\n",
            "   ...\n",
            "   [1.29775848e+02 8.07299194e+01 7.27044678e+01]\n",
            "   [1.03398109e+02 5.17705231e+01 4.82297249e+01]\n",
            "   [1.19974701e+02 6.55461273e+01 6.53318405e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.81377411e+01 1.13774109e+00 1.87092133e+01]\n",
            "   [1.92142639e+01 2.21426392e+00 1.97857361e+01]\n",
            "   [2.03367233e+01 2.78571415e+00 2.05255585e+01]\n",
            "   ...\n",
            "   [3.33162117e+01 1.07193279e+01 3.35050659e+01]\n",
            "   [2.55562859e+01 8.39809608e+00 3.01123905e+01]\n",
            "   [1.85355892e+01 5.47438669e+00 2.60406475e+01]]\n",
            "\n",
            "  [[1.79744854e+01 9.74485159e-01 1.89744854e+01]\n",
            "   [1.80000000e+01 1.00000000e+00 1.90000000e+01]\n",
            "   [1.91989784e+01 2.19897699e+00 2.01989784e+01]\n",
            "   ...\n",
            "   [4.09539566e+01 1.51121464e+01 3.73978539e+01]\n",
            "   [2.24745712e+01 3.34189653e+00 2.54082336e+01]\n",
            "   [2.01681862e+01 5.03041410e+00 2.60763378e+01]]\n",
            "\n",
            "  [[1.76428566e+01 6.42857194e-01 1.86428566e+01]\n",
            "   [1.93316650e+01 2.33166504e+00 2.03316650e+01]\n",
            "   [1.87091751e+01 1.70917606e+00 1.97091751e+01]\n",
            "   ...\n",
            "   [4.81270065e+01 1.93514481e+01 4.24178314e+01]\n",
            "   [2.70253944e+01 3.38260365e+00 2.72397194e+01]\n",
            "   [2.08419323e+01 2.61232948e+00 2.46123295e+01]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[2.10000000e+01 1.30000000e+01 1.10000000e+01]\n",
            "   [2.20000000e+01 1.40000000e+01 1.20000000e+01]\n",
            "   [2.30000000e+01 1.50000000e+01 1.30000000e+01]\n",
            "   ...\n",
            "   [2.00000000e+00 2.00000000e+00 2.00000000e+00]\n",
            "   [1.07144165e+00 1.07144165e+00 1.07144165e+00]\n",
            "   [2.00000000e+00 2.00000000e+00 2.00000000e+00]]\n",
            "\n",
            "  [[2.20000000e+01 1.40000000e+01 1.20000000e+01]\n",
            "   [2.29327164e+01 1.49327173e+01 1.29327173e+01]\n",
            "   [2.32598858e+01 1.52598858e+01 1.32598858e+01]\n",
            "   ...\n",
            "   [2.00000000e+00 2.00000000e+00 1.57147217e+00]\n",
            "   [1.07144165e+00 1.07144165e+00 1.07144165e+00]\n",
            "   [2.00000000e+00 2.00000000e+00 2.00000000e+00]]\n",
            "\n",
            "  [[2.27633934e+01 1.47633934e+01 1.27633934e+01]\n",
            "   [2.37088642e+01 1.57088652e+01 1.37088652e+01]\n",
            "   [2.41635857e+01 1.61635857e+01 1.41635847e+01]\n",
            "   ...\n",
            "   [2.00000000e+00 2.00000000e+00 3.71821404e-01]\n",
            "   [3.08048725e-01 1.83483458e+00 2.53510654e-01]\n",
            "   [1.23660707e+00 2.76339293e+00 2.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[5.79936457e+00 3.79936433e+00 7.27263117e+00]\n",
            "   [3.29115939e+00 2.81789255e+00 5.52779245e+00]\n",
            "   [3.45091915e+00 2.50162625e+00 7.34950495e+00]\n",
            "   ...\n",
            "   [8.83855438e+01 8.13855438e+01 7.33855438e+01]\n",
            "   [8.70615234e+01 7.80615234e+01 7.10615234e+01]\n",
            "   [7.99340591e+01 7.09340591e+01 6.39340630e+01]]\n",
            "\n",
            "  [[4.60556221e+00 2.60556245e+00 7.60556221e+00]\n",
            "   [5.88397217e+00 3.88397217e+00 8.88397217e+00]\n",
            "   [5.89640379e+00 5.11068964e+00 9.46783161e+00]\n",
            "   ...\n",
            "   [8.79875717e+01 8.09875717e+01 7.29875717e+01]\n",
            "   [9.05940628e+01 8.15940628e+01 7.45940628e+01]\n",
            "   [8.21903381e+01 7.31903381e+01 6.61903381e+01]]\n",
            "\n",
            "  [[6.00000000e+00 3.00000000e+00 1.00000000e+01]\n",
            "   [6.68013239e+00 4.68013239e+00 9.68013191e+00]\n",
            "   [5.41546631e+00 4.84403801e+00 9.20118046e+00]\n",
            "   ...\n",
            "   [8.80755615e+01 8.10755615e+01 7.30755615e+01]\n",
            "   [9.04195557e+01 8.14195557e+01 7.44195557e+01]\n",
            "   [8.09909668e+01 7.19909668e+01 6.49909668e+01]]]\n",
            "\n",
            "\n",
            " [[[5.46887741e+01 4.65612221e+01 3.21581612e+01]\n",
            "   [4.94489784e+01 3.92397957e+01 2.38367348e+01]\n",
            "   [5.26326523e+01 3.90051003e+01 2.30051022e+01]\n",
            "   ...\n",
            "   [1.18357132e+02 1.08571426e+02 8.07142487e+01]\n",
            "   [1.18500015e+02 1.10428604e+02 7.47856598e+01]\n",
            "   [1.24086723e+02 1.16086723e+02 7.78010178e+01]]\n",
            "\n",
            "  [[4.28265266e+01 3.86836700e+01 2.88061218e+01]\n",
            "   [4.67193871e+01 3.97142868e+01 2.95000000e+01]\n",
            "   [4.40255089e+01 3.63112259e+01 2.50255108e+01]\n",
            "   ...\n",
            "   [1.21785706e+02 1.15729584e+02 8.38979492e+01]\n",
            "   [1.20137741e+02 1.15862259e+02 8.11428223e+01]\n",
            "   [1.21566330e+02 1.16806114e+02 8.19744873e+01]]\n",
            "\n",
            "  [[3.50408134e+01 3.16122456e+01 2.69642868e+01]\n",
            "   [4.13928566e+01 3.63928566e+01 3.22500000e+01]\n",
            "   [4.21938782e+01 3.56224518e+01 2.80510216e+01]\n",
            "   ...\n",
            "   [1.19336739e+02 1.16474503e+02 8.18571701e+01]\n",
            "   [1.18127518e+02 1.17428574e+02 8.60714645e+01]\n",
            "   [1.17994911e+02 1.16571434e+02 8.67193909e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.06785667e+02 1.01280556e+02 7.37193832e+01]\n",
            "   [1.07413223e+02 1.02413223e+02 7.31989594e+01]\n",
            "   [1.09234703e+02 1.04571404e+02 7.51887894e+01]\n",
            "   ...\n",
            "   [1.10066368e+02 1.03469398e+02 6.95459442e+01]\n",
            "   [1.05683571e+02 9.72295380e+01 6.13978653e+01]\n",
            "   [1.05928497e+02 9.77142334e+01 6.10714417e+01]]\n",
            "\n",
            "  [[1.09168327e+02 1.01168327e+02 7.95050812e+01]\n",
            "   [1.10928558e+02 1.02994881e+02 7.99285812e+01]\n",
            "   [1.12668381e+02 1.05428543e+02 7.96989975e+01]\n",
            "   ...\n",
            "   [1.15387703e+02 1.06260132e+02 7.57754745e+01]\n",
            "   [1.09351952e+02 1.02204033e+02 7.42755051e+01]\n",
            "   [1.08525482e+02 1.02193855e+02 7.57653275e+01]]\n",
            "\n",
            "  [[1.03484634e+02 9.54846344e+01 7.60254745e+01]\n",
            "   [1.10765274e+02 9.97652740e+01 7.96734467e+01]\n",
            "   [1.14714317e+02 1.03714317e+02 8.18673935e+01]\n",
            "   ...\n",
            "   [1.11862305e+02 1.01076599e+02 7.18725662e+01]\n",
            "   [1.10928589e+02 1.03449112e+02 8.05461502e+01]\n",
            "   [1.05199005e+02 9.94847107e+01 8.00714722e+01]]]\n",
            "\n",
            "\n",
            " [[[3.85031891e+01 1.45031891e+01 1.05031891e+01]\n",
            "   [5.22329407e+01 2.92329426e+01 2.32329426e+01]\n",
            "   [4.04531250e+01 2.14531250e+01 1.46674099e+01]\n",
            "   ...\n",
            "   [1.83327847e+01 1.25533514e+01 2.35720825e+00]\n",
            "   [1.85139809e+01 1.04425392e+01 5.59732616e-02]\n",
            "   [7.24530869e+01 6.05463638e+01 2.05020523e+01]]\n",
            "\n",
            "  [[4.05051041e+01 1.57216196e+01 1.17216196e+01]\n",
            "   [5.24536057e+01 2.94536057e+01 2.34536057e+01]\n",
            "   [3.78675079e+01 1.88675060e+01 1.20817919e+01]\n",
            "   ...\n",
            "   [1.80082760e+01 1.26510677e+01 1.29385996e+00]\n",
            "   [2.60952644e+01 1.88073044e+01 7.74057448e-01]\n",
            "   [8.30948486e+01 7.14520264e+01 2.83790169e+01]]\n",
            "\n",
            "  [[4.24822998e+01 1.74823036e+01 1.31764984e+01]\n",
            "   [5.14025841e+01 2.83588982e+01 2.23807411e+01]\n",
            "   [3.62479286e+01 1.63966827e+01 9.54543972e+00]\n",
            "   ...\n",
            "   [1.84882545e+01 1.29167814e+01 6.42791748e-01]\n",
            "   [4.21152611e+01 3.53496246e+01 4.89367390e+00]\n",
            "   [8.56902771e+01 7.75001755e+01 2.76516743e+01]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.65092087e+02 1.62092087e+02 1.55092087e+02]\n",
            "   [1.76070236e+02 1.76004715e+02 1.68026550e+02]\n",
            "   [1.76580276e+02 1.77794556e+02 1.69151703e+02]\n",
            "   ...\n",
            "   [1.14713577e+02 1.13550156e+02 9.96073761e+01]\n",
            "   [1.21126701e+02 1.17339752e+02 1.01835587e+02]\n",
            "   [6.03582001e+01 4.90588150e+01 3.05097771e+01]]\n",
            "\n",
            "  [[1.81300568e+02 1.78300568e+02 1.71300568e+02]\n",
            "   [1.79687027e+02 1.79687027e+02 1.71687027e+02]\n",
            "   [1.77871796e+02 1.79086075e+02 1.70443222e+02]\n",
            "   ...\n",
            "   [1.13391167e+02 1.13319847e+02 9.97483749e+01]\n",
            "   [1.15957207e+02 1.13742882e+02 9.84571152e+01]\n",
            "   [9.21985703e+01 8.31270370e+01 6.37698555e+01]]\n",
            "\n",
            "  [[1.85928131e+02 1.82928131e+02 1.75928131e+02]\n",
            "   [1.81288010e+02 1.81288010e+02 1.73288010e+02]\n",
            "   [1.76437668e+02 1.77651962e+02 1.69009094e+02]\n",
            "   ...\n",
            "   [1.15407112e+02 1.15335793e+02 1.01764320e+02]\n",
            "   [1.10859955e+02 1.08645630e+02 9.33598633e+01]\n",
            "   [1.18363068e+02 1.09291534e+02 8.99343567e+01]]]], shape=(32, 224, 224, 3), dtype=float32) tf.Tensor(\n",
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]], shape=(32, 10), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# See an example batch of data\n",
        "for images, labels in train_data_10_percent.take(1):\n",
        "  print(images, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLA3bPGLKL58"
      },
      "source": [
        "Notice how the image arrays come out as tensors of pixel values where as the labels come out as one-hot encodings (e.g. `[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]` for `hamburger`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5OhOCQi0AQY"
      },
      "source": [
        "### Model 0: Building a transfer learning model using the Keras Functional API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAALkDqzKIqe",
        "outputId": "e38eaa61-b1e7-4584-ecdf-5e585d801486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
            "24274472/24274472 [==============================] - 0s 0us/step\n",
            "Shape after base_model: (None, 7, 7, 1280)\n",
            "After GlobalAveragePooling2D(): (None, 1280)\n",
            "Saving TensorBoard log files to: transfer_learning/10_percent_feature_extract/20240328-160700\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 18s 257ms/step - loss: 1.9043 - accuracy: 0.3947 - val_loss: 1.3286 - val_accuracy: 0.7368\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 4s 167ms/step - loss: 1.1651 - accuracy: 0.7440 - val_loss: 0.9184 - val_accuracy: 0.7993\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 5s 180ms/step - loss: 0.8561 - accuracy: 0.8093 - val_loss: 0.7137 - val_accuracy: 0.8273\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 4s 171ms/step - loss: 0.7000 - accuracy: 0.8400 - val_loss: 0.6193 - val_accuracy: 0.8388\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 4s 141ms/step - loss: 0.5969 - accuracy: 0.8720 - val_loss: 0.5631 - val_accuracy: 0.8438\n"
          ]
        }
      ],
      "source": [
        "# 1. Create base model with tf.keras.applications\n",
        "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\n",
        "\n",
        "# OLD\n",
        "# base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "# 2. Freeze the base model (so the pre-learned patterns remain)\n",
        "base_model.trainable = False\n",
        "\n",
        "# 3. Create inputs into the base model\n",
        "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
        "\n",
        "# 4. If using ResNet50V2, add this to speed up convergence, remove for EfficientNetV2\n",
        "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
        "\n",
        "# 5. Pass the inputs to the base_model (note: using tf.keras.applications, EfficientNetV2 inputs don't have to be normalized)\n",
        "x = base_model(inputs)\n",
        "# Check data shape after passing it to base_model\n",
        "print(f\"Shape after base_model: {x.shape}\")\n",
        "\n",
        "# 6. Average pool the outputs of the base model (aggregate all the most important information, reduce number of computations)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "print(f\"After GlobalAveragePooling2D(): {x.shape}\")\n",
        "\n",
        "# 7. Create the output activation layer\n",
        "outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "# 8. Combine the inputs with the outputs into a model\n",
        "model_0 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 9. Compile the model\n",
        "model_0.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# 10. Fit the model (we use less steps for validation so it's faster)\n",
        "history_10_percent = model_0.fit(train_data_10_percent,\n",
        "                                 epochs=5,\n",
        "                                 steps_per_epoch=len(train_data_10_percent),\n",
        "                                 validation_data=test_data_10_percent,\n",
        "                                 # Go through less of the validation data so epochs are faster (we want faster experiments!)\n",
        "                                 validation_steps=int(0.25 * len(test_data_10_percent)),\n",
        "                                 # Track our model's training logs for visualization later\n",
        "                                 callbacks=[create_tensorboard_callback(\"transfer_learning\", \"10_percent_feature_extract\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TopEk0fk0Gan"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOFivIHOV4WyKiEGDecbvOm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}